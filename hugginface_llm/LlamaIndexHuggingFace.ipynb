{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.llamaindex.ai/en/stable/examples/llm/huggingface/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-huggingface in /Users/danielmoreno/NLP/lib/python3.11/site-packages (0.1.4)\n",
      "Requirement already satisfied: huggingface-hub<0.21.0,>=0.20.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-llms-huggingface) (0.20.3)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-llms-huggingface) (0.10.20.post2)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-llms-huggingface) (2.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.38.2)\n",
      "Requirement already satisfied: filelock in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (2024.3.1)\n",
      "Requirement already satisfied: requests in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (24.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.14.1)\n",
      "Requirement already satisfied: pandas in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (10.2.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.9.0)\n",
      "Requirement already satisfied: sympy in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.28.0)\n",
      "Requirement already satisfied: psutil in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.9.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2.6.4)\n",
      "Requirement already satisfied: anyio in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.0.4)\n",
      "Requirement already satisfied: idna in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.3.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests->huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests->huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /Users/danielmoreno/NLP/lib/python3.11/site-packages (4.38.2)\n",
      "Requirement already satisfied: huggingface_hub[inference] in /Users/danielmoreno/NLP/lib/python3.11/site-packages (0.20.3)\n",
      "Requirement already satisfied: filelock in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: torch in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface_hub[inference]) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface_hub[inference]) (4.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface_hub[inference]) (3.9.3)\n",
      "Requirement already satisfied: pydantic<3.0,>1.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface_hub[inference]) (2.6.4)\n",
      "Requirement already satisfied: psutil in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pydantic<3.0,>1.1->huggingface_hub[inference]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pydantic<3.0,>1.1->huggingface_hub[inference]) (2.16.3)\n",
      "Requirement already satisfied: sympy in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp->huggingface_hub[inference]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp->huggingface_hub[inference]) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp->huggingface_hub[inference]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp->huggingface_hub[inference]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp->huggingface_hub[inference]) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests->transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers[torch]\" \"huggingface_hub[inference]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/danielmoreno/NLP/lib/python3.11/site-packages (0.10.20)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.2.0,>=0.1.4 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.10)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.20 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.10.20.post2)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.11)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.14.1)\n",
      "Requirement already satisfied: pandas in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.2)\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.23.26)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.4.0,>=0.3.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.3.9)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.9.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.6.4)\n",
      "Requirement already satisfied: anyio in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.4)\n",
      "Requirement already satisfied: idna in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.9.0)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.23.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "from llama_index.llms.huggingface import (\n",
    "    HuggingFaceInferenceAPI,\n",
    "    HuggingFaceLLM,\n",
    ")\n",
    "\n",
    "# SEE: https://huggingface.co/docs/hub/security-tokens\n",
    "# We just need a token with read permissions for this demo\n",
    "HF_TOKEN: Optional[str] = os.getenv(\"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\")\n",
    "# NOTE: None default will fall back on Hugging Face's token storage\n",
    "# when this token gets used within HuggingFaceInferenceAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00008.safetensors: 100%|██████████| 1.89G/1.89G [02:35<00:00, 12.2MB/s]\n",
      "model-00002-of-00008.safetensors: 100%|██████████| 1.95G/1.95G [02:16<00:00, 14.2MB/s]\n",
      "model-00003-of-00008.safetensors: 100%|██████████| 1.98G/1.98G [02:12<00:00, 15.0MB/s]\n",
      "model-00004-of-00008.safetensors: 100%|██████████| 1.95G/1.95G [02:29<00:00, 13.0MB/s]\n",
      "model-00005-of-00008.safetensors: 100%|██████████| 1.98G/1.98G [02:17<00:00, 14.4MB/s]\n",
      "model-00006-of-00008.safetensors: 100%|██████████| 1.95G/1.95G [02:22<00:00, 13.7MB/s]\n",
      "model-00007-of-00008.safetensors: 100%|██████████| 1.98G/1.98G [02:37<00:00, 12.6MB/s]\n",
      "model-00008-of-00008.safetensors: 100%|██████████| 816M/816M [00:59<00:00, 13.6MB/s]\n",
      "Downloading shards: 100%|██████████| 8/8 [17:51<00:00, 133.95s/it]\n",
      "/Users/danielmoreno/NLP/lib/python3.11/site-packages/accelerate/utils/modeling.py:1341: UserWarning: Current model requires 1073750016 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:03<00:00,  2.39it/s]\n",
      "generation_config.json: 100%|██████████| 111/111 [00:00<00:00, 93.5kB/s]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.\n",
      "tokenizer_config.json: 100%|██████████| 264/264 [00:00<00:00, 835kB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 10.9MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<00:00, 186kB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "WARNING:llama_index.llms.huggingface.base:The model `HuggingFaceH4/zephyr-7b-alpha` and tokenizer `StabilityAI/stablelm-tuned-alpha-3b` are different, please ensure that they are compatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1079.2653770446777 seconds\n",
      "Time taken: 0.0004239082336425781 seconds\n",
      "Time taken: 0.00016689300537109375 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Task  has no recommended model. Please specify a model explicitly. Visit https://huggingface.co/tasks for more info.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremotely_run_anon_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mremotely_run_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# If you don't provide a model_name to the HuggingFaceInferenceAPI,\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Hugging Face's recommended model gets used (thanks to huggingface_hub)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m remotely_run_recommended \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceInferenceAPI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHF_TOKEN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m remotely_run_recommended_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremotely_run_recommended_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mremotely_run_anon_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/NLP/lib/python3.11/site-packages/llama_index/llms/huggingface/base.py:501\u001b[0m, in \u001b[0;36mHuggingFaceInferenceAPI.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m     task \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# NOTE: task being None or empty string leads to ValueError,\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# which ensures model is present\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mInferenceClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_recommended_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Hugging Face\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms recommended model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m given task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/NLP/lib/python3.11/site-packages/huggingface_hub/inference/_client.py:1935\u001b[0m, in \u001b[0;36mInferenceClient.get_recommended_model\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m   1933\u001b[0m model \u001b[38;5;241m=\u001b[39m _fetch_recommended_models()\u001b[38;5;241m.\u001b[39mget(task)\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1936\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no recommended model. Please specify a model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m explicitly. Visit https://huggingface.co/tasks for more info.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1938\u001b[0m     )\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mValueError\u001b[0m: Task  has no recommended model. Please specify a model explicitly. Visit https://huggingface.co/tasks for more info."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "current_time = time.time()\n",
    "\n",
    "# This uses https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha\n",
    "# downloaded (if first invocation) to the local Hugging Face model cache,\n",
    "# and actually runs the model on your local machine's hardware\n",
    "locally_run = HuggingFaceLLM(model_name=\"HuggingFaceH4/zephyr-7b-alpha\")\n",
    "locally_run_time = time.time()\n",
    "print(f\"Time taken: {locally_run_time - current_time} seconds\")\n",
    "# This will use the same model, but run remotely on Hugging Face's servers,\n",
    "# accessed via the Hugging Face Inference API\n",
    "# Note that using your token will not charge you money,\n",
    "# the Inference API is free it just has rate limits\n",
    "remotely_run = HuggingFaceInferenceAPI(\n",
    "    model_name=\"HuggingFaceH4/zephyr-7b-alpha\", token=HF_TOKEN\n",
    ")\n",
    "\n",
    "remotely_run_time = time.time()\n",
    "print(f\"Time taken: {remotely_run_time - locally_run_time} seconds\")\n",
    "# Or you can skip providing a token, using Hugging Face Inference API anonymously\n",
    "remotely_run_anon = HuggingFaceInferenceAPI(\n",
    "    model_name=\"HuggingFaceH4/zephyr-7b-alpha\"\n",
    ")\n",
    "remotely_run_anon_time = time.time()\n",
    "print(f\"Time taken: {remotely_run_anon_time - remotely_run_time} seconds\")\n",
    "# If you don't provide a model_name to the HuggingFaceInferenceAPI,\n",
    "# Hugging Face's recommended model gets used (thanks to huggingface_hub)\n",
    "remotely_run_recommended = HuggingFaceInferenceAPI(token=HF_TOKEN)\n",
    "remotely_run_recommended_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {remotely_run_recommended_time - remotely_run_anon_time} seconds\")\n",
    "\n",
    "\n",
    "finished_time = time.time()\n",
    "print(f\"Time taken: {finished_time - current_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as Google Colab from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.29.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting numpy>=1.17 (from accelerate)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting packaging>=20.0 (from accelerate)\n",
      "  Using cached packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting psutil (from accelerate)\n",
      "  Using cached psutil-5.9.8-cp38-abi3-macosx_11_0_arm64.whl.metadata (21 kB)\n",
      "Collecting pyyaml (from accelerate)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting torch>=1.10.0 (from accelerate)\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting huggingface-hub (from accelerate)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors>=0.3.1 (from accelerate)\n",
      "  Using cached safetensors-0.4.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from torch>=1.10.0->accelerate)\n",
      "  Using cached filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch>=1.10.0->accelerate)\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch>=1.10.0->accelerate)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.10.0->accelerate)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch>=1.10.0->accelerate)\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting fsspec (from torch>=1.10.0->accelerate)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting requests (from huggingface-hub->accelerate)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub->accelerate)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.10.0->accelerate)\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub->accelerate)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface-hub->accelerate)\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub->accelerate)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface-hub->accelerate)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.10.0->accelerate)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading accelerate-0.29.1-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Using cached safetensors-0.4.2-cp311-cp311-macosx_11_0_arm64.whl (393 kB)\n",
      "Downloading torch-2.2.2-cp311-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "Using cached psutil-5.9.8-cp38-abi3-macosx_11_0_arm64.whl (249 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Using cached filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl (18 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, safetensors, pyyaml, psutil, packaging, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, jinja2, torch, huggingface-hub, accelerate\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Uninstalling typing_extensions-4.10.0:\n",
      "      Successfully uninstalled typing_extensions-4.10.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.2\n",
      "    Uninstalling tqdm-4.66.2:\n",
      "      Successfully uninstalled tqdm-4.66.2\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.4.2\n",
      "    Uninstalling safetensors-0.4.2:\n",
      "      Successfully uninstalled safetensors-0.4.2\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.8\n",
      "    Uninstalling psutil-5.9.8:\n",
      "      Successfully uninstalled psutil-5.9.8\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.2.1\n",
      "    Uninstalling networkx-3.2.1:\n",
      "      Successfully uninstalled networkx-3.2.1\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.5\n",
      "    Uninstalling MarkupSafe-2.1.5:\n",
      "      Successfully uninstalled MarkupSafe-2.1.5\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.6\n",
      "    Uninstalling idna-3.6:\n",
      "      Successfully uninstalled idna-3.6\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.3.1\n",
      "    Uninstalling fsspec-2024.3.1:\n",
      "      Successfully uninstalled fsspec-2024.3.1\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.13.1\n",
      "    Uninstalling filelock-3.13.1:\n",
      "      Successfully uninstalled filelock-3.13.1\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.2.2\n",
      "    Uninstalling certifi-2024.2.2:\n",
      "      Successfully uninstalled certifi-2024.2.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.3\n",
      "    Uninstalling Jinja2-3.1.3:\n",
      "      Successfully uninstalled Jinja2-3.1.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.1\n",
      "    Uninstalling torch-2.2.1:\n",
      "      Successfully uninstalled torch-2.2.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.28.0\n",
      "    Uninstalling accelerate-0.28.0:\n",
      "      Successfully uninstalled accelerate-0.28.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-llms-huggingface 0.1.4 requires huggingface-hub<0.21.0,>=0.20.3, but you have huggingface-hub 0.22.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 accelerate-0.29.1 certifi-2024.2.2 charset-normalizer-3.3.2 filelock-3.13.3 fsspec-2024.3.1 huggingface-hub-0.22.2 idna-3.6 jinja2-3.1.3 mpmath-1.3.0 networkx-3.3 numpy-1.26.4 packaging-24.0 psutil-5.9.8 pyyaml-6.0.1 requests-2.31.0 safetensors-0.4.2 sympy-1.12 torch-2.2.2 tqdm-4.66.2 typing-extensions-4.11.0 urllib3-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/danielmoreno/NLP/lib/python3.11/site-packages (0.10.20)\n",
      "Requirement already satisfied: llama-index-llms-huggingface in /Users/danielmoreno/NLP/lib/python3.11/site-packages (0.1.4)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /Users/danielmoreno/NLP/lib/python3.11/site-packages (0.1.4)\n",
      "Requirement already satisfied: transformers in /Users/danielmoreno/NLP/lib/python3.11/site-packages (4.38.2)\n",
      "Requirement already satisfied: accelerate in /Users/danielmoreno/NLP/lib/python3.11/site-packages (0.28.0)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting llama-index-readers-web\n",
      "  Downloading llama_index_readers_web-0.1.8-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.2.0,>=0.1.4 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.10)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.20 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.10.20.post2)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.11)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: huggingface-hub<0.21.0,>=0.20.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-llms-huggingface) (0.20.3)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-llms-huggingface) (2.2.1)\n",
      "Requirement already satisfied: filelock in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: psutil in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Collecting scipy (from bitsandbytes)\n",
      "  Using cached scipy-1.13.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-web) (3.9.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-web) (4.12.3)\n",
      "Collecting chromedriver-autoinstaller<0.7.0,>=0.6.3 (from llama-index-readers-web)\n",
      "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting html2text<2021.0.0,>=2020.1.16 (from llama-index-readers-web)\n",
      "  Downloading html2text-2020.1.16-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting newspaper3k<0.3.0,>=0.2.8 (from llama-index-readers-web)\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web)\n",
      "  Downloading playwright-1.42.0-py3-none-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Collecting selenium<5.0.0,>=4.17.2 (from llama-index-readers-web)\n",
      "  Downloading selenium-4.19.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.1.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-web) (2.2.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.9.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-web) (2.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (4.10.0)\n",
      "Requirement already satisfied: pydantic<3.0,>1.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.4)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.0.28)\n",
      "Requirement already satisfied: dataclasses-json in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.8)\n",
      "Requirement already satisfied: httpx in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.8.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.14.1)\n",
      "Requirement already satisfied: pandas in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (10.2.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.9.0)\n",
      "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.2)\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.23.26)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.4.0,>=0.3.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.3.9)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting lxml>=3.6.0 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading lxml-5.2.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba3k>=0.35.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: greenlet==3.0.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (3.0.3)\n",
      "Collecting pyee==11.0.1 (from playwright<2.0,>=1.30->llama-index-readers-web)\n",
      "  Downloading pyee-11.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Collecting trio~=0.17 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading trio-0.25.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: sympy in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.16.0)\n",
      "Requirement already satisfied: six in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from feedfinder2>=0.0.4->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (1.16.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: anyio in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.4)\n",
      "Requirement already satisfied: sniffio in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.3.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.16.3)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.23.22)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading requests_file-2.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.0)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/danielmoreno/NLP/lib/python3.11/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
      "Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_readers_web-0.1.8-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
      "Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading playwright-1.42.0-py3-none-macosx_11_0_arm64.whl (32.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.6/32.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pyee-11.0.1-py3-none-any.whl (15 kB)\n",
      "Downloading selenium-4.19.0-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached scipy-1.13.0-cp311-cp311-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-5.2.1-cp311-cp311-macosx_10_9_universal2.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.25.0-py3-none-any.whl (467 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13538 sha256=a499765fa7570b6b20dd2426e496a2a2f4c1b5d0a923c8bf3db6d61b027a814d\n",
      "  Stored in directory: /Users/danielmoreno/Library/Caches/pip/wheels/fc/ab/f8/cce3a9ae6d828bd346be695f7ff54612cd22b7cbd7208d68f3\n",
      "  Building wheel for feedfinder2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3340 sha256=fa649b2110d50282f2e37a15dc626f0c6f4b4b216771cff4655d459b07861aa3\n",
      "  Stored in directory: /Users/danielmoreno/Library/Caches/pip/wheels/80/d5/72/9cd9eccc819636436c6a6e59c22a0fb1ec167beef141f56491\n",
      "  Building wheel for jieba3k (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398382 sha256=c6a7a569fdb5944b70786c615fea7f03e383f9552311fe8f2936eb9a79857dc1\n",
      "  Stored in directory: /Users/danielmoreno/Library/Caches/pip/wheels/3a/a1/46/8e68055c1713f9c4598774c15ad0541f26d5425ee7423b6493\n",
      "  Building wheel for sgmllib3k (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=fe6db1bd6b495977a61d0a4b645be95e9a45d6a9f3cff07f2386f65a3848260b\n",
      "  Stored in directory: /Users/danielmoreno/Library/Caches/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sortedcontainers, sgmllib3k, jieba3k, wsproto, scipy, pysocks, pyee, outcome, lxml, html2text, feedparser, cssselect, chromedriver-autoinstaller, trio, requests-file, playwright, feedfinder2, bitsandbytes, trio-websocket, tldextract, selenium, newspaper3k, llama-index-readers-web\n",
      "Successfully installed bitsandbytes-0.42.0 chromedriver-autoinstaller-0.6.4 cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.11 html2text-2020.1.16 jieba3k-0.35.1 llama-index-readers-web-0.1.8 lxml-5.2.1 newspaper3k-0.2.8 outcome-1.3.0.post0 playwright-1.42.0 pyee-11.0.1 pysocks-1.7.1 requests-file-2.0.0 scipy-1.13.0 selenium-4.19.0 sgmllib3k-1.0.0 sortedcontainers-2.4.0 tinysegmenter-0.3 tldextract-5.1.2 trio-0.25.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index llama-index-llms-huggingface llama-index-embeddings-huggingface transformers accelerate bitsandbytes llama-index-readers-web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m   prompt \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|assistant|>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m prompt\n\u001b[0;32m---> 32\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHuggingFaceH4/zephyr-7b-alpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHuggingFaceH4/zephyr-7b-alpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_wrapper_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<|system|>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m</s>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m<|user|>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{query_str}\u001b[39;49;00m\u001b[38;5;124;43m</s>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m<|assistant|>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3900\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# tokenizer_kwargs={},\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages_to_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages_to_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NLP/lib/python3.11/site-packages/llama_index/llms/huggingface/base.py:161\u001b[0m, in \u001b[0;36mHuggingFaceLLM.__init__\u001b[0;34m(self, context_window, max_new_tokens, query_wrapper_prompt, tokenizer_name, model_name, model, tokenizer, device_map, stopping_ids, tokenizer_kwargs, tokenizer_outputs_to_remove, model_kwargs, generate_kwargs, is_chat_model, callback_manager, system_prompt, messages_to_prompt, completion_to_prompt, pydantic_program_mode, output_parser)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize params.\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m model_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# check context_window\u001b[39;00m\n\u001b[1;32m    166\u001b[0m config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/NLP/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m )\n",
      "File \u001b[0;32m~/NLP/lib/python3.11/site-packages/transformers/modeling_utils.py:3024\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\n\u001b[1;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3027\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[1;32m   3028\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
      "File \u001b[0;32m~/NLP/lib/python3.11/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:62\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.validate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_environment\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[0;32m---> 62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m         )\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "def messages_to_prompt(messages):\n",
    "  prompt = \"\"\n",
    "  for message in messages:\n",
    "    if message.role == 'system':\n",
    "      prompt += f\"<|system|>\\n{message.content}</s>\\n\"\n",
    "    elif message.role == 'user':\n",
    "      prompt += f\"<|user|>\\n{message.content}</s>\\n\"\n",
    "    elif message.role == 'assistant':\n",
    "      prompt += f\"<|assistant|>\\n{message.content}</s>\\n\"\n",
    "\n",
    "  # ensure we start with a system prompt, insert blank if needed\n",
    "  if not prompt.startswith(\"<|system|>\\n\"):\n",
    "    prompt = \"<|system|>\\n</s>\\n\" + prompt\n",
    "\n",
    "  # add final assistant prompt\n",
    "  prompt = prompt + \"<|assistant|>\\n\"\n",
    "\n",
    "  return prompt\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    model_name=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
    "    tokenizer_name=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
    "    query_wrapper_prompt=PromptTemplate(\"<|system|>\\n</s>\\n<|user|>\\n{query_str}</s>\\n<|assistant|>\\n\"),\n",
    "    context_window=3900,\n",
    "    max_new_tokens=256,\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    # tokenizer_kwargs={},\n",
    "    generate_kwargs={\"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95},\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
